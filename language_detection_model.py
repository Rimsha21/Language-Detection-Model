# -*- coding: utf-8 -*-
"""Language Detection Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yGj1xz-v2yiHRmJizV-sug8Yv0s_RQ46
"""



"""**Languages are: **


* English

* Portuguese

* French

* Greek

* Dutch

* Spanish

* Japanese

* Russian

* Danish

* Italian

* Turkish

* Swedish

* Arabic

* Malayalam

* Hindi

* Tamil

* Telugu
"""



"""**APPLICATIONS**

These kinds of prediction systems are widely used in electronic devices such as mobiles, laptops, etc for machine translation, and also on robots. It helps in tracking and identifying multilingual documents too
"""

import pandas as pd
import numpy as np
import re
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.simplefilter("ignore")

import io
from google.colab import files
files= files.upload()

df = pd.read_csv(io.BytesIO(files['Language Detection.csv']))

df.head()

df["Language"].value_counts()

X = df["Text"]
y = df["Language"]

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

"""**Text Preprocessing**"""

# creating a list for appending the preprocessed text
data_list = []
# iterating through all the text
for text in X:
       # removing the symbols and numbers
        text = re.sub(r'[!@#$(),n"%^*?:;~`0-9]', ' ', text)
        text = re.sub(r'[[]]', ' ', text)
        # converting the text to lower case
        text = text.lower()
        # appending to data_list
        data_list.append(text)

"""**Bag of Words**"""

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
X = cv.fit_transform(data_list).toarray()
X.shape

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)

from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()
model.fit(x_train, y_train)

y_pred = model.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
ac = accuracy_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)

print("Accuracy is :",ac)

plt.figure(figsize=(15,10))
sns.heatmap(cm, annot = True)
plt.show()

"""**Predicting with some more data**"""

def predict(text):
     x = cv.transform([text]).toarray() # converting text to bag of words model (Vector)
     lang = model.predict(x) # predicting the language
     lang = le.inverse_transform(lang) # finding the language corresponding the the predicted value
     print("The langauge is in",lang[0]) # printing the language

predict('And we almost there, the model creation part. We are using the naive_bayes algorithm for our model creation. Later we are training the model using the training set.')

predict('आजकल के समय में निबंध लिखना एक महत्वपूर्ण विषय बन चुका है, खासतौर से छात्रों के लिए। ऐसे कई अवसर आते हैं, जब आपको विभिन्न विषयों पर निबंधों की आवश्यकता होती है। निबंधों के इसी महत्व को ध्यान में रखते हुए हमने इन निबंधों को तैयार किया है। हमारे द्वारा तैयार किये गये निबंध बहुत ही क्रमबद्ध तथा सरल हैं और हमारे वेबसाइट पर छोटे तथा बड़े दोनो प्रकार की शब्द सीमाओं के निबंध उपलब्ध हैं।')

